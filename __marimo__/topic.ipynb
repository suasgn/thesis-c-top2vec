{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SvWM",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install marimo datasets top2vec[sentence-transformers] numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.15 (main, Sep  9 2024, 22:43:48) [Clang 18.1.8 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import marimo as mo\n",
    "import re\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# modified top2vec library\n",
    "from _top2vec import Top2Vec\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if cuda or mps available, if available, use one of them, otherwise use cpu\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     print(\"using cuda\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "#     # os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = (\n",
    "#     #     \"1\"  # This is tracked as pytorch issue #98222\n",
    "#     # )\n",
    "#     print(\"using mps\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _detokenize_sentence(tokens):\n",
    "    if isinstance(tokens, list):\n",
    "        return \" \".join([t for t in tokens if isinstance(t, str)]).strip()\n",
    "    if isinstance(tokens, str):\n",
    "        return tokens.strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_full_paragraph_and_summary(data):\n",
    "    paragraph_sentences = []\n",
    "    summary_sentences = []\n",
    "\n",
    "    for each_paragraph in data[\"paragraphs\"]:\n",
    "        for each_sentence in each_paragraph:\n",
    "            paragraph_sentences.append(_detokenize_sentence(each_sentence))\n",
    "\n",
    "    for each_summary in data[\"summary\"]:\n",
    "        summary_sentences.append(_detokenize_sentence(each_summary))\n",
    "\n",
    "    paragraph = \" \".join([s for s in paragraph_sentences if s]).strip()\n",
    "    summary = \" \".join([s for s in summary_sentences if s]).strip()\n",
    "    return {\"document\": paragraph, \"summary\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"joshuasiagian/indosum\")\n",
    "\n",
    "ds = ds.map(\n",
    "    get_full_paragraph_and_summary, remove_columns=ds[\"train\"].column_names\n",
    ")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the first 5 data in the dataset\n",
    "print(json.dumps(ds[\"train\"][:1], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ds[\"train\"][\"document\"]\n",
    "\n",
    "# Basic cleaning: strip whitespace and remove empty entries\n",
    "documents = [\n",
    "    d.strip() for d in documents if isinstance(d, str) and len(d.strip()) > 0\n",
    "]\n",
    "\n",
    "len(documents)\n",
    "\n",
    "top2vec_model = Top2Vec(\n",
    "    documents=documents,\n",
    "    ngram_vocab=True,\n",
    "    contextual_top2vec=True,\n",
    "    # embedding_model=\"paraphrase-multilingual-MiniLM-L12-v2\",  # modified top2vec. The original top2vec only supports \"all-MiniLM-L6-v2\" and \"all-mpnet-base-v2\"\n",
    "    embedding_model=\"all-mpnet-base-v2\",\n",
    ")\n",
    "\n",
    "top2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _():\n",
    "    # Inspect topics learned by the model\n",
    "    num_topics = top2vec_model.get_num_topics()\n",
    "    topic_sizes, topic_nums = top2vec_model.get_topic_sizes()\n",
    "    top_terms_per_topic = []\n",
    "    for topic_num in topic_nums:\n",
    "        words, word_scores, _ = top2vec_model.get_topics(topic_num)\n",
    "        top_terms_per_topic.append(\n",
    "            {\n",
    "                \"topic\": int(topic_num),\n",
    "                \"size\": int(topic_sizes[topic_nums.tolist().index(topic_num)]),\n",
    "                \"top_terms\": words[:10],\n",
    "                \"term_scores\": word_scores[:10].tolist(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Display a compact summary\n",
    "    summary = {\n",
    "        \"num_topics\": int(num_topics),\n",
    "        \"largest_topics\": [\n",
    "            {\n",
    "                \"topic\": int(topic_nums[i]),\n",
    "                \"size\": int(topic_sizes[i]),\n",
    "                \"top_terms\": top_terms_per_topic[i][\"top_terms\"],\n",
    "            }\n",
    "            for i in range(min(10, len(topic_nums)))\n",
    "        ],\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "\n",
    "_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for later reuse\n",
    "model_path = \"models/top2vec_indosum_mpnet\"\n",
    "top2vec_model.save(model_path)\n",
    "{\"saved_path\": model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count documents with top topic score higher/lower than 0.7\n",
    "threshold = 0.5\n",
    "high_score_count = 0\n",
    "low_score_count = 0\n",
    "\n",
    "docs = None\n",
    "if hasattr(top2vec_model, \"documents\") and top2vec_model.documents is not None:\n",
    "    docs = top2vec_model.documents\n",
    "else:\n",
    "    try:\n",
    "        docs, _, _ = top2vec_model.get_documents(\n",
    "            list(range(top2vec_model.get_num_documents()))\n",
    "        )\n",
    "    except Exception:\n",
    "        docs = None\n",
    "\n",
    "if docs is None:\n",
    "    raise ValueError(\n",
    "        \"Cannot access documents from model. Ensure keep_documents=True when training.\"\n",
    "    )\n",
    "\n",
    "topic_dist = top2vec_model.get_document_topic_distribution()\n",
    "# topic_sizes, topic_nums = top2vec_model.get_topic_sizes()\n",
    "\n",
    "for _doc_id in range(len(docs)):\n",
    "    _dist = topic_dist[_doc_id]\n",
    "    top_score = _dist.max()\n",
    "    if top_score > threshold:\n",
    "        high_score_count += 1\n",
    "    else:\n",
    "        low_score_count += 1\n",
    "\n",
    "print(f\"Documents with top topic score > {threshold}: {high_score_count}\")\n",
    "print(f\"Documents with top topic score <= {threshold}: {low_score_count}\")\n",
    "print(f\"Total documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {},
   "source": [
    "## Embedding models\n",
    "\n",
    "### paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "Documents with top topic score > 0.5: 10569\n",
    "Documents with top topic score <= 0.5: 3693\n",
    "Total documents: 14262\n",
    "\n",
    "Documents with top topic score > 0.7: 7432\n",
    "Documents with top topic score <= 0.7: 6830\n",
    "Total documents: 14262\n",
    "\n",
    "### all-MiniLM-L6-v2\n",
    "\n",
    "Documents with top topic score > 0.5: 4248\n",
    "Documents with top topic score <= 0.5: 10014\n",
    "Total documents: 14262\n",
    "\n",
    "\n",
    "Documents with top topic score > 0.7: 1160\n",
    "Documents with top topic score <= 0.7: 13102\n",
    "Total documents: 14262\n",
    "\n",
    "### all-mpnet-base-v2\n",
    "\n",
    "Documents with top topic score > 0.5: 12920\n",
    "Documents with top topic score <= 0.5: 1342\n",
    "Total documents: 14262\n",
    "\n",
    "\n",
    "\n",
    "Documents with top topic score > 0.7: 10813\n",
    "Documents with top topic score <= 0.7: 3449\n",
    "Total documents: 14262"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "auto_download": [
     "html",
     "ipynb"
    ],
    "width": "full"
   },
   "marimo_version": "0.19.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
